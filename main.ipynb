{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть для считывания знаков STOP с рисунка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразоавние .json меток в .txt в формате, удобном для yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"./dataset/ds/img\"\n",
    "annotations_dir = \"./dataset/ds/ann\"\n",
    "output_dir = \"./dataset/ds/yolo_labels\"\n",
    "meta_file = \"./dataset/meta.json\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta_data = json.load(f)\n",
    "\n",
    "classes = { cls[\"title\"].lower(): idx for idx, cls in enumerate(meta_data[\"classes\"]) }\n",
    "\n",
    "if \"stop\" not in classes:\n",
    "    raise ValueError(\"Класс 'stop' не найден в meta.json!\")\n",
    "\n",
    "def normalize_bbox(bbox, img_width, img_height):\n",
    "    x_min, y_min = bbox[0]\n",
    "    x_max, y_max = bbox[1]\n",
    "    x_center = (x_min + x_max) / 2 / img_width\n",
    "    y_center = (y_min + y_max) / 2 / img_height\n",
    "    width = (x_max - x_min) / img_width\n",
    "    height = (y_max - y_min) / img_height\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "for annotation_file in os.listdir(annotations_dir):\n",
    "    if annotation_file.endswith(\".json\"):\n",
    "        with open(os.path.join(annotations_dir, annotation_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        img_width = data[\"size\"][\"width\"]\n",
    "        img_height = data[\"size\"][\"height\"]\n",
    "        \n",
    "        yolo_labels = []\n",
    "        for obj in data[\"objects\"]:\n",
    "            class_title = obj[\"classTitle\"].lower()\n",
    "            if class_title == \"stop\": \n",
    "                bbox = obj[\"points\"][\"exterior\"]\n",
    "                x_center, y_center, width, height = normalize_bbox(bbox, img_width, img_height)\n",
    "                yolo_labels.append(f\"0 {x_center} {y_center} {width} {height}\")\n",
    "        \n",
    "        image_name = os.path.splitext(annotation_file)[0].replace('.png', '.txt')\n",
    "        label_file = os.path.join(output_dir, image_name)\n",
    "        \n",
    "        with open(label_file, \"w\") as f:\n",
    "            if yolo_labels: \n",
    "                f.write(\"\\n\".join(yolo_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных на тренировачные, валидационные и тестируемые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"./dataset/ds/img\"\n",
    "labels_dir = \"./dataset/ds/yolo_labels\"\n",
    "dataset_dir = \"./data\"\n",
    "train_images_dir = os.path.join(dataset_dir, \"train\", \"images\")\n",
    "train_labels_dir = os.path.join(dataset_dir, \"train\", \"labels\")\n",
    "val_images_dir = os.path.join(dataset_dir, \"valid\", \"images\")\n",
    "val_labels_dir = os.path.join(dataset_dir, \"valid\", \"labels\")\n",
    "test_images_dir = os.path.join(dataset_dir, \"test\", \"images\")\n",
    "test_labels_dir = os.path.join(dataset_dir, \"test\", \"labels\")\n",
    "\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "\n",
    "random.shuffle(image_files)\n",
    "\n",
    "test_size = 0.2  # 20% для теста\n",
    "val_size = 0.1   # 10% для валидации\n",
    "split_index_test = int(len(image_files) * (1 - test_size))\n",
    "split_index_val = int(len(image_files) * (1 - test_size - val_size))\n",
    "\n",
    "train_files = image_files[:split_index_val]\n",
    "val_files = image_files[split_index_val:split_index_test]\n",
    "test_files = image_files[split_index_test:]\n",
    "\n",
    "for file in train_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(train_images_dir, file))\n",
    "    shutil.copy(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(train_labels_dir, file.replace('.png', '.txt')))\n",
    "\n",
    "for file in val_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(val_images_dir, file))\n",
    "    shutil.copy(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(val_labels_dir, file.replace('.png', '.txt')))\n",
    "\n",
    "for file in test_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(test_images_dir, file))\n",
    "    shutil.copy(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(test_labels_dir, file.replace('.png', '.txt')))\n",
    "    \n",
    "shutil.rmtree(\"./dataset/ds/yolo_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!yolo detect train data=data.yaml model=yolov8n.pt epochs=50 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.103  Python-3.11.0 torch-2.0.1+cpu CPU (AMD Ryzen 7 7730U with Radeon Graphics)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Projects\\PetProjects\\StopSignDetector\\dataset\\test\\labels.cache... 176 images, 157 backgrounds, 0 corrupt: 100%|██████████| 176/176 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:15<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        176         19      0.944          1      0.993      0.875\n",
      "Speed: 1.6ms preprocess, 82.3ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Projects\\PetProjects\\StopSignDetector\\runs\\detect\\val4\u001b[0m\n",
      "Quality functionality mAP50: 99.25%\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/train5/weights/best.pt\")  \n",
    "metrics = model.val(data=\"data.yaml\", split=\"test\")\n",
    "print(f\"Quality functionality mAP50: { round(metrics.box.map50 * 100, 5) }%\")  # Основная метрика"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
